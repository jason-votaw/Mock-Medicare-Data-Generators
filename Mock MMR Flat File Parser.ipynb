{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65523d79-2964-485e-8f45-1c296ec6f16b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# MMR Flat File to CSV Parser - Converts the generated MMR flat file to CSV\n",
    "# For use in Databricks environment\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Any\n",
    "import re\n",
    "\n",
    "class MMRFlatFileParser:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the parser with the exact field definitions matching the generator.\n",
    "        Each field is defined as: (start_position, width, field_name, data_type, description)\n",
    "        Positions are 0-based for Python string slicing.\n",
    "        \"\"\"\n",
    "        self.field_definitions = [\n",
    "            (0, 5, \"contract_number\", \"str\", \"Plan Contract Number\"),\n",
    "            (5, 8, \"run_date\", \"date\", \"Date the file was produced (YYYYMMDD)\"),\n",
    "            (13, 6, \"payment_date\", \"date\", \"Payment month for the report (YYYYMM)\"),\n",
    "            (19, 12, \"beneficiary_id\", \"str\", \"HICN/MBI Beneficiary ID\"),\n",
    "            (31, 7, \"surname\", \"str\", \"Beneficiary last name\"),\n",
    "            (38, 1, \"first_initial\", \"str\", \"First initial of beneficiary\"),\n",
    "            (39, 1, \"sex_code\", \"str\", \"Beneficiary Sex Code: M/F\"),\n",
    "            (40, 8, \"date_of_birth\", \"date\", \"Beneficiary date of birth (YYYYMMDD)\"),\n",
    "            (48, 4, \"filler1\", \"filler\", \"Spaces\"),\n",
    "            (52, 5, \"state_county_code\", \"str\", \"Beneficiary State and County Code\"),\n",
    "            (57, 1, \"out_of_area_indicator\", \"flag\", \"Out of Area indicator\"),\n",
    "            (58, 1, \"part_a_entitlement\", \"flag\", \"Part A entitlement indicator\"),\n",
    "            (59, 1, \"part_b_entitlement\", \"flag\", \"Part B entitlement indicator\"),\n",
    "            (60, 1, \"hospice\", \"flag\", \"Hospice status indicator\"),\n",
    "            (61, 1, \"esrd\", \"flag\", \"ESRD indicator\"),\n",
    "            (62, 1, \"aged_disabled_msp\", \"flag\", \"Aged/Disabled MSP indicator\"),\n",
    "            (63, 1, \"filler2\", \"filler\", \"Spaces\"),\n",
    "            (64, 1, \"filler3\", \"filler\", \"Spaces\"),\n",
    "            (65, 1, \"new_medicare_medicaid_flag\", \"flag\", \"New Medicare Beneficiary Medicaid Status\"),\n",
    "            (66, 1, \"lti_flag\", \"flag\", \"Long Term Institutional Status\"),\n",
    "            (67, 1, \"medicaid_addon_indicator\", \"flag\", \"Medicaid Add-on Factor Indicator\"),\n",
    "            (68, 2, \"filler4\", \"filler\", \"Spaces\"),\n",
    "            (70, 1, \"default_risk_factor_code\", \"str\", \"Default Risk Adjustment Factor Code\"),\n",
    "            (71, 7, \"risk_adjustment_factor_a\", \"decimal\", \"Part A Risk Adjustment Factor\"),\n",
    "            (78, 7, \"risk_adjustment_factor_b\", \"decimal\", \"Part B Risk Adjustment Factor\"),\n",
    "            (85, 2, \"payment_months_part_a\", \"int\", \"Payment/Adjustment Months Part A\"),\n",
    "            (87, 2, \"payment_months_part_b\", \"int\", \"Payment/Adjustment Months Part B\"),\n",
    "            (89, 2, \"adjustment_reason_code\", \"str\", \"Adjustment Reason Code (ARC)\"),\n",
    "            (91, 8, \"payment_start_date\", \"date\", \"Payment/Adjustment Start Date\"),\n",
    "            (99, 8, \"payment_end_date\", \"date\", \"Payment/Adjustment End Date\"),\n",
    "            (107, 9, \"filler5\", \"filler\", \"Spaces\"),\n",
    "            (116, 9, \"filler6\", \"filler\", \"Spaces\"),\n",
    "            (125, 9, \"monthly_risk_adjusted_amount_a\", \"amount\", \"Monthly Risk Adjusted Amount Part A\"),\n",
    "            (134, 9, \"monthly_risk_adjusted_amount_b\", \"amount\", \"Monthly Risk Adjusted Amount Part B\"),\n",
    "            (143, 8, \"lis_premium_subsidy\", \"amount\", \"LIS Premium Subsidy\"),\n",
    "            (151, 1, \"esrd_msp_flag\", \"str\", \"ESRD MSP Flag\"),\n",
    "            (152, 10, \"mtm_addon\", \"amount\", \"Medication Therapy Management Add On\"),\n",
    "            (162, 8, \"part_d_manufacturer_discount\", \"amount\", \"Part D Manufacturer Discount Amount\"),\n",
    "            (170, 1, \"medicaid_dual_status\", \"str\", \"Medicaid Full/Partial/Non-dual\"),\n",
    "            (171, 4, \"risk_adjustment_age_group\", \"str\", \"Risk Adjustment Age Group (RAAG)\"),\n",
    "            (175, 7, \"filler7\", \"filler\", \"Spaces\"),\n",
    "            (182, 1, \"filler8\", \"filler\", \"Spaces\"),\n",
    "            (183, 1, \"filler9\", \"filler\", \"Spaces\"),\n",
    "            (184, 3, \"plan_benefit_package_id\", \"str\", \"Plan Benefit Package ID\"),\n",
    "            (187, 1, \"filler10\", \"filler\", \"Spaces\"),\n",
    "            (188, 2, \"risk_adjustment_factor_type\", \"str\", \"Risk Adjustment Factor Type Code\"),\n",
    "            (190, 1, \"frailty_indicator\", \"flag\", \"Frailty Indicator (PACE/FIDE SNP)\"),\n",
    "            (191, 1, \"orec\", \"str\", \"Original Reason for Entitlement Code\"),\n",
    "            (192, 1, \"filler11\", \"filler\", \"Spaces\"),\n",
    "            (193, 3, \"segment_number\", \"str\", \"Segment Number\"),\n",
    "            (196, 1, \"filler12\", \"filler\", \"Spaces\"),\n",
    "            (197, 1, \"eghp_flag\", \"flag\", \"EGHP Flag\"),\n",
    "            (198, 8, \"part_c_basic_premium_a\", \"amount\", \"Part C Basic Premium – Part A Amount\"),\n",
    "            (206, 8, \"part_c_basic_premium_b\", \"amount\", \"Part C Basic Premium – Part B Amount\"),\n",
    "            (214, 8, \"rebate_part_a_cost_sharing\", \"amount\", \"Rebate for Part A Cost Sharing Reduction\"),\n",
    "            (222, 8, \"rebate_part_b_cost_sharing\", \"amount\", \"Rebate for Part B Cost Sharing Reduction\"),\n",
    "            (230, 8, \"rebate_part_a_supplemental\", \"amount\", \"Rebate for Other Part A Mandatory Supplemental Benefits\"),\n",
    "            (238, 8, \"rebate_part_b_supplemental\", \"amount\", \"Rebate for Other Part B Mandatory Supplemental Benefits\"),\n",
    "            (246, 8, \"rebate_part_b_premium_reduction_a\", \"amount\", \"Rebate for Part B Premium Reduction – Part A Amount\"),\n",
    "            (254, 135, \"filler13\", \"filler\", \"Large filler section (positions 255-389)\"),\n",
    "            (389, 2, \"payment_months_part_d\", \"int\", \"Payment/Adjustment Months Part D\"),\n",
    "            (391, 10, \"pace_premium_addon\", \"amount\", \"PACE Premium Add On\"),\n",
    "            (401, 10, \"pace_cost_sharing_addon\", \"amount\", \"PACE Cost Sharing Add-on\"),\n",
    "            (411, 7, \"part_c_frailty_factor\", \"decimal\", \"Part C Frailty Factor\"),\n",
    "            (418, 7, \"msp_reduction_factor\", \"decimal\", \"MSP Reduction Factor\"),\n",
    "            (425, 10, \"msp_reduction_amount_a\", \"amount\", \"MSP Reduction Amount Part A\"),\n",
    "            (435, 10, \"msp_reduction_amount_b\", \"amount\", \"MSP Reduction Amount Part B\"),\n",
    "            (445, 2, \"medicaid_dual_status_code\", \"str\", \"Medicaid Dual Status Code\"),\n",
    "            (447, 8, \"part_d_coverage_gap_discount\", \"amount\", \"Part D Coverage Gap Discount Amount\"),\n",
    "            (455, 2, \"part_d_risk_adjustment_type\", \"str\", \"Part D Risk Adjustment Factor Type\"),\n",
    "            (457, 1, \"filler14\", \"filler\", \"Filler\"),\n",
    "            (458, 9, \"part_a_monthly_rate\", \"amount\", \"Part A Monthly Rate for Payment or Adjustment\"),\n",
    "            (467, 9, \"part_b_monthly_rate\", \"amount\", \"Part B Monthly Rate for Payment or Adjustment\"),\n",
    "            (476, 9, \"part_d_monthly_rate\", \"amount\", \"Part D Monthly Rate for Payment or Adjustment\"),\n",
    "            (485, 10, \"cleanup_id\", \"str\", \"Cleanup ID\")\n",
    "        ]\n",
    "        \n",
    "        # Create lookup dictionary for field names\n",
    "        self.field_dict = {field[2]: field for field in self.field_definitions}\n",
    "        \n",
    "        # Verify total length\n",
    "        total_length = max(pos + width for pos, width, _, _, _ in self.field_definitions)\n",
    "        # print(f\"Parser configured for records of {total_length} characters\")\n",
    "    \n",
    "    def parse_field_value(self, raw_value: str, data_type: str, field_name: str = \"\") -> Any:\n",
    "        \"\"\"\n",
    "        Parse and convert field values based on their data type.\n",
    "        \n",
    "        Args:\n",
    "            raw_value (str): Raw field value from flat file\n",
    "            data_type (str): Expected data type\n",
    "            field_name (str): Field name for context\n",
    "            \n",
    "        Returns:\n",
    "            Any: Converted value\n",
    "        \"\"\"\n",
    "        # Clean the raw value\n",
    "        cleaned_value = raw_value.strip()\n",
    "        \n",
    "        if data_type == \"filler\":\n",
    "            return None  # Don't include filler fields in output\n",
    "        \n",
    "        elif data_type == \"str\":\n",
    "            return cleaned_value if cleaned_value else None\n",
    "        \n",
    "        elif data_type == \"int\":\n",
    "            if cleaned_value:\n",
    "                try:\n",
    "                    return int(cleaned_value)\n",
    "                except ValueError:\n",
    "                    return None\n",
    "            return None\n",
    "        \n",
    "        elif data_type == \"decimal\":\n",
    "            if cleaned_value and cleaned_value.strip():\n",
    "                try:\n",
    "                    return float(cleaned_value)\n",
    "                except ValueError:\n",
    "                    return None\n",
    "            return None\n",
    "        \n",
    "        elif data_type == \"amount\":\n",
    "            if cleaned_value and cleaned_value.strip():\n",
    "                try:\n",
    "                    # Handle monetary amounts with decimal points\n",
    "                    return float(cleaned_value)\n",
    "                except ValueError:\n",
    "                    return None\n",
    "            return None\n",
    "        \n",
    "        elif data_type == \"date\":\n",
    "            if cleaned_value:\n",
    "                try:\n",
    "                    if len(cleaned_value) == 8:  # YYYYMMDD format\n",
    "                        date_obj = datetime.strptime(cleaned_value, \"%Y%m%d\")\n",
    "                        return date_obj.strftime(\"%Y-%m-%d\")\n",
    "                    elif len(cleaned_value) == 6:  # YYYYMM format\n",
    "                        date_obj = datetime.strptime(cleaned_value, \"%Y%m\")\n",
    "                        return date_obj.strftime(\"%Y-%m\")\n",
    "                    else:\n",
    "                        return cleaned_value\n",
    "                except ValueError:\n",
    "                    return cleaned_value\n",
    "            return None\n",
    "        \n",
    "        elif data_type == \"flag\":\n",
    "            # Convert Y/N flags to integer 1/0, space to None\n",
    "            if cleaned_value == \"Y\":\n",
    "                return int(1)\n",
    "            elif cleaned_value == \"N\":\n",
    "                return int(0)\n",
    "            else:\n",
    "                return None\n",
    "        \n",
    "        else:\n",
    "            return cleaned_value if cleaned_value else None\n",
    "    \n",
    "    def parse_record(self, record_line: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Parse a single record from the MMR flat file.\n",
    "        \n",
    "        Args:\n",
    "            record_line (str): Single line from the flat file\n",
    "            \n",
    "        Returns:\n",
    "            Dict[str, Any]: Parsed field values\n",
    "        \"\"\"\n",
    "        # Ensure the line is long enough\n",
    "        record_line = record_line.ljust(495)\n",
    "        \n",
    "        parsed_record = {}\n",
    "        \n",
    "        for start_pos, width, field_name, data_type, description in self.field_definitions:\n",
    "            # Extract the raw field value\n",
    "            end_pos = start_pos + width\n",
    "            raw_value = record_line[start_pos:end_pos]\n",
    "            \n",
    "            # Parse the value based on its type\n",
    "            parsed_value = self.parse_field_value(raw_value, data_type, field_name)\n",
    "            \n",
    "            # Only include non-filler fields\n",
    "            if data_type != \"filler\":\n",
    "                parsed_record[field_name] = parsed_value\n",
    "        \n",
    "        return parsed_record\n",
    "    \n",
    "    def parse_flat_file(self, file_path: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Parse the entire MMR flat file and return as DataFrame.\n",
    "        \n",
    "        Args:\n",
    "            file_path (str): Path to the MMR flat file\n",
    "            \n",
    "        Returns:\n",
    "            pd.DataFrame: Parsed data\n",
    "        \"\"\"\n",
    "        records = []\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                for line_num, line in enumerate(file, 1):\n",
    "                    line = line.rstrip('\\n\\r')\n",
    "                    \n",
    "                    if line.strip():  # Skip empty lines\n",
    "                        try:\n",
    "                            parsed_record = self.parse_record(line)\n",
    "                            parsed_record['record_number'] = line_num\n",
    "                            records.append(parsed_record)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error parsing line {line_num}: {e}\")\n",
    "                            continue\n",
    "        \n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error reading file: {e}\")\n",
    "        \n",
    "        if not records:\n",
    "            raise ValueError(\"No valid records found in file\")\n",
    "        \n",
    "        df = pd.DataFrame(records)\n",
    "        return df\n",
    "    \n",
    "    def parse_flat_file_string(self, file_content: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Parse MMR flat file content from a string.\n",
    "        \n",
    "        Args:\n",
    "            file_content (str): Content of the MMR flat file\n",
    "            \n",
    "        Returns:\n",
    "            pd.DataFrame: Parsed data\n",
    "        \"\"\"\n",
    "        records = []\n",
    "        lines = file_content.split('\\n')\n",
    "        \n",
    "        for line_num, line in enumerate(lines, 1):\n",
    "            line = line.rstrip('\\r')\n",
    "            \n",
    "            if line.strip():  # Skip empty lines\n",
    "                try:\n",
    "                    parsed_record = self.parse_record(line)\n",
    "                    parsed_record['record_number'] = line_num\n",
    "                    records.append(parsed_record)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error parsing line {line_num}: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        if not records:\n",
    "            raise ValueError(\"No valid records found in content\")\n",
    "        \n",
    "        df = pd.DataFrame(records)\n",
    "        return df\n",
    "    \n",
    "    def export_to_csv(self, df: pd.DataFrame, output_path: str):\n",
    "        \"\"\"\n",
    "        Export DataFrame to clean CSV format.\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): Parsed MMR data\n",
    "            output_path (str): Output CSV file path\n",
    "        \"\"\"\n",
    "        df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "    \n",
    "    def get_field_summary(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Generate a summary of parsed fields.\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): Parsed MMR data\n",
    "            \n",
    "        Returns:\n",
    "            pd.DataFrame: Field summary statistics\n",
    "        \"\"\"\n",
    "        summary_data = []\n",
    "        \n",
    "        for _, _, field_name, data_type, description in self.field_definitions:\n",
    "            if data_type != \"filler\" and field_name in df.columns:\n",
    "                col = df[field_name]\n",
    "                \n",
    "                summary_info = {\n",
    "                    'field_name': field_name,\n",
    "                    'data_type': data_type,\n",
    "                    'description': description,\n",
    "                    'total_records': len(col),\n",
    "                    'non_null_count': col.notna().sum(),\n",
    "                    'null_count': col.isna().sum(),\n",
    "                    'unique_values': col.nunique(),\n",
    "                    'sample_values': str(col.dropna().head(3).tolist())[:100]\n",
    "                }\n",
    "                \n",
    "                summary_data.append(summary_info)\n",
    "        \n",
    "        return pd.DataFrame(summary_data)\n",
    "\n",
    "# Databricks-specific functions\n",
    "def read_mmr_from_dbfs(dbfs_path: str) -> str:\n",
    "    \"\"\"Read MMR file from Databricks File System.\"\"\"\n",
    "    try:\n",
    "        with open(f\"/dbfs{dbfs_path}\", 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error reading from DBFS: {e}\")\n",
    "\n",
    "def mmr_to_spark_dataframe(file_content: str, spark_session):\n",
    "    \"\"\"Convert MMR content to Spark DataFrame for Databricks.\"\"\"\n",
    "    parser = MMRFlatFileParser()\n",
    "    pandas_df = parser.parse_flat_file_string(file_content)\n",
    "    return spark_session.createDataFrame(pandas_df)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize parser\n",
    "    parser = MMRFlatFileParser()\n",
    "    \n",
    "    # Parse the flat file and export to clean CSV\n",
    "    try:\n",
    "        df = parser.parse_flat_file(\"mmr_mock_flatfile.txt\")\n",
    "        parser.export_to_csv(df, \"mmr_parsed_output.csv\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"MMR flat file not found. Run the generator first to create 'mmr_mock_flatfile.txt'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Mock MMR Flat File Parser",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}